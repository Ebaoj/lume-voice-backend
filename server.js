/**
 * Voice AI MVP Server
 *
 * Fluxo:
 * 1. Cliente envia √°udio via WebSocket
 * 2. Streaming para Deepgram (STT)
 * 3. Transcri√ß√£o enviada para ChatGPT (LLM)
 * 4. Resposta do ChatGPT enviada para ElevenLabs (TTS)
 * 5. √Åudio sintetizado retorna ao cliente
 */

require('dotenv').config();
const express = require('express');
const http = require('http');
const WebSocket = require('ws');
const { createClient } = require('@deepgram/sdk');
const OpenAI = require('openai');
const axios = require('axios');

// ===== Configura√ß√£o =====
const PORT = process.env.PORT || 3000;
const app = express();
const server = http.createServer(app);
const wss = new WebSocket.Server({ server });

// Servir arquivos est√°ticos (HTML/CSS/JS do cliente)
app.use(express.static('public'));

// System prompt para o personagem "Beto"
const SYSTEM_PROMPT = `Voc√™ √© Beto, atendente de uma cafeteria.
Seja muito breve e natural (1-2 frases). Ajude o cliente a escolher bebidas.
Fale como em uma conversa r√°pida, sem formalidades.`;

// FIX #11: Limite de mensagens no hist√≥rico (evita estouro de tokens)
const MAX_CONVERSATION_HISTORY = 10;

// ===== WebSocket Handler =====
wss.on('connection', (ws) => {
  console.log('‚úì Novo cliente conectado');

  let deepgramLive = null;
  let conversationHistory = [];
  let isProcessing = false;
  let lastFinalTranscript = ''; // Guardar √∫ltima transcri√ß√£o final
  let processingTimeout = null; // Timeout para processar ap√≥s sil√™ncio
  let currentTTSAbortController = null; // FIX #12: Para cancelar TTS em andamento

  // API Keys ser√£o fornecidas pelo cliente
  let apiKeys = {
    deepgram: null,
    openai: null,
    elevenlabs: null
  };

  // Clientes dos SDKs (criados ap√≥s receber as keys)
  let deepgramClient = null;
  let openaiClient = null;

  // System prompt customizado (vem do frontend)
  let customSystemPrompt = null;

  ws.on('message', async (message) => {
    try {
      // Converter Buffer para string se necess√°rio
      let messageStr = message;
      if (Buffer.isBuffer(message)) {
        messageStr = message.toString('utf8');
      }

      // Mensagens podem ser comandos (string) ou √°udio (buffer bin√°rio)
      // Verificar se √© JSON v√°lido
      let data;
      try {
        data = JSON.parse(messageStr);
      } catch (e) {
        // N√£o √© JSON, ent√£o √© √°udio bin√°rio
        if (deepgramLive) {
          deepgramLive.send(message);
        }
        return;
      }

      // Se chegou aqui, √© um comando JSON
      if (data && data.type) {

        // Comando: configurar API keys
        if (data.type === 'configure') {
          console.log('‚Üí Configurando API keys');

          // Limpar e validar keys
          apiKeys.deepgram = (data.keys.deepgram || '').trim();
          apiKeys.openai = (data.keys.openai || '').trim();
          apiKeys.elevenlabs = (data.keys.elevenlabs || '').trim();

          // Capturar system prompt customizado
          if (data.systemPrompt) {
            customSystemPrompt = data.systemPrompt;
            console.log('‚Üí System prompt customizado recebido:', customSystemPrompt.substring(0, 100) + '...');
          }

          console.log('‚Üí Deepgram key:', apiKeys.deepgram.substring(0, 8) + '...' + apiKeys.deepgram.substring(apiKeys.deepgram.length - 4));
          console.log('‚Üí Deepgram key length:', apiKeys.deepgram.length);

          // Inicializar clientes com as keys fornecidas
          try {
            // Criar cliente Deepgram (sem config adicional, igual ao test-deepgram.js que funciona)
            deepgramClient = createClient(apiKeys.deepgram);

            openaiClient = new OpenAI({
              apiKey: apiKeys.openai,
            });

            ws.send(JSON.stringify({
              type: 'configured',
              message: 'APIs configuradas com sucesso!'
            }));
            console.log('‚úì APIs configuradas');
          } catch (error) {
            console.error('‚úó Erro ao criar clientes:', error);
            ws.send(JSON.stringify({
              type: 'error',
              message: 'Erro ao configurar APIs: ' + error.message
            }));
          }
          return;
        }

        // Comando: iniciar streaming de √°udio
        if (data.type === 'start') {
          console.log('‚Üí Iniciando sess√£o de √°udio');

          // Verificar se as APIs foram configuradas
          if (!deepgramClient || !openaiClient) {
            ws.send(JSON.stringify({
              type: 'error',
              message: 'Configure as API keys primeiro!'
            }));
            return;
          }

          // Verificar se a key do Deepgram est√° v√°lida
          if (!apiKeys.deepgram || apiKeys.deepgram.length < 10) {
            ws.send(JSON.stringify({
              type: 'error',
              message: 'API key do Deepgram inv√°lida!'
            }));
            return;
          }

          // FIX #1: MEMORY LEAK - Limpar listeners antigos antes de criar nova conex√£o
          if (deepgramLive) {
            console.log('‚Üí Limpando conex√£o Deepgram anterior...');
            deepgramLive.removeAllListeners();
            deepgramLive.finish();
            deepgramLive = null;
          }

          // Criar conex√£o de streaming com Deepgram
          console.log('‚Üí Criando conex√£o Deepgram...');
          try {
            deepgramLive = deepgramClient.listen.live({
              model: 'nova-2',
              language: 'pt-BR',
              encoding: 'linear16',
              sample_rate: 16000,
              interim_results: true,
              vad_events: true,
              // Configura√ß√µes para evitar interrup√ß√µes prematuras
              endpointing: 800, // Esperar 800ms de sil√™ncio antes de considerar fim de fala
              utterance_end_ms: 1200, // Tempo extra para pausas longas (pensando)
            });
            console.log('‚úì Conex√£o Deepgram criada');
          } catch (error) {
            console.error('‚úó Erro ao criar conex√£o live:', error);
            ws.send(JSON.stringify({
              type: 'error',
              message: 'Erro ao criar conex√£o com Deepgram: ' + error.message
            }));
            return;
          }

          // ===== Deepgram Event Handlers =====
          console.log('‚Üí Registrando event handlers do Deepgram...');

          // Quando Deepgram estiver pronto
          deepgramLive.on('open', () => {
            console.log('‚úÖ ‚úÖ ‚úÖ Deepgram OPEN event disparado! Conex√£o estabelecida!');
            // S√≥ agora avisar o cliente que pode come√ßar a enviar √°udio
            ws.send(JSON.stringify({ type: 'deepgram_ready' }));
          });

          // Resultado de transcri√ß√£o (parcial ou final)
          deepgramLive.on('Results', async (data) => {
            console.log('üìä Results event recebido');
            const transcript = data.channel?.alternatives[0]?.transcript;

            if (transcript && transcript.trim().length > 0) {
              const isFinal = data.is_final;

              // Enviar transcri√ß√£o para o cliente (para debug visual)
              ws.send(JSON.stringify({
                type: 'transcript',
                text: transcript,
                isFinal: isFinal
              }));

              console.log(`${isFinal ? '‚úì' : '...'} Transcri√ß√£o: ${transcript}`);

              // Se √© final, guardar e agendar processamento
              if (isFinal) {
                lastFinalTranscript = transcript;

                // Limpar timeout anterior
                if (processingTimeout) {
                  clearTimeout(processingTimeout);
                }

                // Agendar processamento ap√≥s 1000ms de sil√™ncio (dar tempo para pensar)
                processingTimeout = setTimeout(async () => {
                  if (!isProcessing && lastFinalTranscript && lastFinalTranscript.trim().length > 0) {
                    const transcriptToProcess = lastFinalTranscript;
                    lastFinalTranscript = '';

                    isProcessing = true;
                    ws.send(JSON.stringify({ type: 'status', message: 'Processando...' }));

                    console.log(`üìù Processando transcri√ß√£o: "${transcriptToProcess}"`);
                    await processWithGPT(transcriptToProcess, ws);
                    isProcessing = false;
                  }
                }, 1000);
              }
            }
          });

          // Utterance End - usu√°rio parou de falar
          deepgramLive.on('UtteranceEnd', async () => {
            console.log('‚Üí Fim de fala detectado');

            if (isProcessing) {
              console.log('‚ö† J√° processando uma resposta, ignorando...');
              return;
            }

            // Usar a √∫ltima transcri√ß√£o final guardada
            if (lastFinalTranscript && lastFinalTranscript.trim().length > 0) {
              const transcriptToProcess = lastFinalTranscript;
              lastFinalTranscript = ''; // Limpar para n√£o processar novamente

              isProcessing = true;
              ws.send(JSON.stringify({ type: 'status', message: 'Processando...' }));

              console.log(`üìù Processando transcri√ß√£o: "${transcriptToProcess}"`);

              // Processar com ChatGPT e gerar resposta em voz
              await processWithGPT(transcriptToProcess, ws);

              isProcessing = false;
            } else {
              console.log('‚ö† Nenhuma transcri√ß√£o final para processar');
            }
          });

          // Erros do Deepgram
          deepgramLive.on('error', (error) => {
            console.error('‚ùå ‚ùå ‚ùå ERRO DEEPGRAM:', {
              type: typeof error,
              message: error.message,
              error: JSON.stringify(error, null, 2),
              keys: Object.keys(error),
              errorString: error.toString(),
              stack: error.stack
            });

            // Tentar extrair mais informa√ß√µes
            if (error.event) {
              console.error('  Error event:', error.event);
            }
            if (error.reason) {
              console.error('  Reason:', error.reason);
            }

            ws.send(JSON.stringify({
              type: 'error',
              message: `Erro no STT: ${error.message || error.reason || 'Verifique sua API key do Deepgram'}`
            }));
          });

          deepgramLive.on('close', (closeEvent) => {
            console.error('üî¥ DEEPGRAM CLOSE EVENT:', {
              type: closeEvent.type,
              code: closeEvent.code,
              reason: closeEvent.reason,
              wasClean: closeEvent.wasClean,
              timestamp: closeEvent.timeStamp,
              all: JSON.stringify(closeEvent, null, 2)
            });
          });

          deepgramLive.on('warning', (warning) => {
            console.warn('‚ö†Ô∏è ‚ö†Ô∏è WARNING DEEPGRAM:', warning);
          });

          deepgramLive.on('Metadata', (metadata) => {
            console.log('‚ÑπÔ∏è ‚ÑπÔ∏è METADATA DEEPGRAM:', metadata);
          });

          // Tentar capturar eventos de mensagem
          if (deepgramLive._ws) {
            console.log('‚Üí WebSocket interno encontrado, adicionando listeners...');
            deepgramLive._ws.on('message', (msg) => {
              console.log('üì® WS Message:', msg.toString());
            });
          }

          console.log('‚úì Todos os event handlers registrados');
        }

        // FIX #12: Comando: interromper bot (usu√°rio come√ßou a falar)
        if (data.type === 'interrupt') {
          console.log('‚ö†Ô∏è  Interrup√ß√£o detectada - cancelando TTS em andamento');

          // Cancelar TTS em andamento
          if (currentTTSAbortController) {
            currentTTSAbortController.abort();
            currentTTSAbortController = null;
          }

          // Avisar cliente para limpar fila de √°udio
          ws.send(JSON.stringify({ type: 'clear_audio_queue' }));

          isProcessing = false;
          return;
        }

        // Comando: parar streaming
        if (data.type === 'stop') {
          console.log('‚Üí Encerrando sess√£o de √°udio');
          if (processingTimeout) {
            clearTimeout(processingTimeout);
            processingTimeout = null;
          }
          if (currentTTSAbortController) {
            currentTTSAbortController.abort();
            currentTTSAbortController = null;
          }
          if (deepgramLive) {
            deepgramLive.finish();
            deepgramLive = null;
          }
          conversationHistory = [];
          lastFinalTranscript = '';
          isProcessing = false;
        }
      }
    } catch (error) {
      console.error('‚úó Erro ao processar mensagem:', error);
      ws.send(JSON.stringify({ type: 'error', message: error.message }));
    }
  });

  // Cliente desconectou
  ws.on('close', () => {
    console.log('‚úó Cliente desconectado');
    if (deepgramLive) {
      deepgramLive.finish();
    }
  });

  // ===== Fun√ß√£o: Processar com ChatGPT STREAMING e gerar TTS =====
  async function processWithGPT(userMessage, ws) {
    const startTime = Date.now();

    try {
      // FIX #9: SANITIZAR LOGS - n√£o logar conte√∫do das mensagens (pode ter PII)
      console.log(`‚Üí Enviando para ChatGPT (length: ${userMessage.length})`);

      // Adicionar mensagem do usu√°rio ao hist√≥rico
      conversationHistory.push({
        role: 'user',
        content: userMessage
      });

      // FIX #11: Limitar hist√≥rico (evita estouro de contexto e custo alto)
      if (conversationHistory.length > MAX_CONVERSATION_HISTORY) {
        conversationHistory = conversationHistory.slice(-MAX_CONVERSATION_HISTORY);
        console.log(`‚ö†Ô∏è  Hist√≥rico limitado a ${MAX_CONVERSATION_HISTORY} mensagens`);
      }

      // Preparar mensagens incluindo system prompt
      const messages = [
        {
          role: 'system',
          content: customSystemPrompt || SYSTEM_PROMPT // Usar prompt customizado ou fallback para padr√£o
        },
        ...conversationHistory
      ];

      // FIX #6: TIMEOUTS - Chamar OpenAI com timeout (evita travar se API ficar lenta)
      const gptStart = Date.now();

      // Timeout manual (OpenAI SDK n√£o tem timeout configur√°vel no streaming)
      const timeoutPromise = new Promise((_, reject) => {
        setTimeout(() => reject(new Error('OpenAI timeout ap√≥s 15s')), 15000);
      });

      const streamPromise = openaiClient.chat.completions.create({
        model: 'gpt-4o', // Modelo mais inteligente para personagens mais profundos
        max_tokens: 250, // Mais espa√ßo para respostas elaboradas
        temperature: 0.8, // Um pouco mais criativo
        messages: messages,
        stream: true,
        stream_options: { include_usage: true }, // Incluir informa√ß√µes de token usage
      });

      const stream = await Promise.race([streamPromise, timeoutPromise]);

      let fullResponse = '';
      let sentenceBuffer = '';
      let firstChunk = true;
      let sentenceCount = 0;
      let tokenUsage = null; // Armazenar info de usage

      // Processar stream chunk por chunk
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';

        // Capturar usage info (vem no √∫ltimo chunk)
        if (chunk.usage) {
          tokenUsage = chunk.usage;
        }

        if (content) {
          if (firstChunk) {
            const firstTokenTime = Date.now() - gptStart;
            console.log(`‚ö° Primeiro token ChatGPT (${firstTokenTime}ms)`);
            firstChunk = false;
          }

          fullResponse += content;
          sentenceBuffer += content;

          // Detectar fim de frase (., ?, !, \n)
          const sentenceEndMatch = sentenceBuffer.match(/[.!?]\s|[.!?]$|\n/);
          if (sentenceEndMatch) {
            const sentence = sentenceBuffer.trim();
            if (sentence.length > 0) {
              sentenceCount++;
              // FIX #9: N√£o logar conte√∫do da frase (PII)
              console.log(`üì§ Frase ${sentenceCount} (${sentence.length} chars)`);

              // Enviar frase para o cliente (debug visual)
              ws.send(JSON.stringify({
                type: 'response_partial',
                text: sentence
              }));

              // üöÄ INOVA√á√ÉO: Gerar TTS da frase imediatamente (await para sequencial)
              await generateTTS(sentence, ws).catch(err => {
                console.error('Erro TTS frase:', err);
              });

              sentenceBuffer = ''; // Limpar buffer
            }
          }
        }
      }

      // Processar √∫ltimo peda√ßo se sobrou
      if (sentenceBuffer.trim().length > 0) {
        console.log(`üì§ Frase final: "${sentenceBuffer.trim()}"`);
        ws.send(JSON.stringify({
          type: 'response_partial',
          text: sentenceBuffer.trim()
        }));
        await generateTTS(sentenceBuffer.trim(), ws);
      }

      const gptTime = Date.now() - gptStart;
      // FIX #9: N√£o logar resposta completa (PII)
      console.log(`‚úì ChatGPT completo (${gptTime}ms, ${fullResponse.length} chars)`);

      // Adicionar resposta ao hist√≥rico
      conversationHistory.push({
        role: 'assistant',
        content: fullResponse
      });

      // Enviar resposta completa
      ws.send(JSON.stringify({
        type: 'response',
        text: fullResponse
      }));

      // Enviar informa√ß√µes de token usage para o frontend
      if (tokenUsage) {
        ws.send(JSON.stringify({
          type: 'token_usage',
          usage: {
            prompt_tokens: tokenUsage.prompt_tokens,
            completion_tokens: tokenUsage.completion_tokens,
            total_tokens: tokenUsage.total_tokens
          }
        }));
        console.log(`üìä Tokens: ${tokenUsage.prompt_tokens} input + ${tokenUsage.completion_tokens} output = ${tokenUsage.total_tokens} total`);
      }

      const totalTime = Date.now() - startTime;
      console.log(`‚è±Ô∏è Tempo total pipeline: ${totalTime}ms`);

    } catch (error) {
      console.error('‚úó Erro ao processar com ChatGPT:', error);
      ws.send(JSON.stringify({
        type: 'error',
        message: 'Erro ao processar com LLM'
      }));
    }
  }

  // ===== Fun√ß√£o: Gerar TTS com ElevenLabs (Streaming) =====
  async function generateTTS(text, ws) {
    const ttsStart = Date.now();

    try {
      console.log(`‚Üí Gerando √°udio com ElevenLabs (${text.length} chars)...`);

      const voiceId = process.env.ELEVENLABS_VOICE_ID || '21m00Tcm4TlvDq8ikWAM';
      const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream`;

      // FIX #12: AbortController para cancelar TTS se usu√°rio interromper
      currentTTSAbortController = new AbortController();

      // FIX #6: Timeout para ElevenLabs (evita travar)
      const response = await axios.post(url, {
        text: text,
        model_id: 'eleven_turbo_v2_5',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.75
        },
        optimize_streaming_latency: 4
      }, {
        headers: {
          'Accept': 'audio/mpeg',
          'xi-api-key': apiKeys.elevenlabs,
          'Content-Type': 'application/json'
        },
        responseType: 'stream',
        timeout: 10000, // 10s timeout
        signal: currentTTSAbortController.signal // Permitir cancelamento
      });

      const ttsTime = Date.now() - ttsStart;
      console.log(`‚úì Stream de √°udio iniciado (${ttsTime}ms)`);

      // Enviar sinal de in√≠cio
      ws.send(JSON.stringify({ type: 'audio_start' }));

      // FIX #8: Fazer streaming dos chunks de √°udio com BACKPRESSURE
      let firstChunk = true;
      response.data.on('data', (chunk) => {
        if (firstChunk) {
          const firstChunkTime = Date.now() - ttsStart;
          console.log(`üéµ Primeiro chunk de √°udio (${firstChunkTime}ms)`);
          firstChunk = false;
        }

        // Verificar backpressure (buffer do WebSocket)
        if (ws.bufferedAmount > 1024 * 1024) { // 1MB
          console.warn('‚ö†Ô∏è  Backpressure detectada, pausando stream');
          response.data.pause();

          // Retomar quando buffer diminuir
          const checkBuffer = setInterval(() => {
            if (ws.bufferedAmount < 512 * 1024) { // 512KB
              console.log('‚úì Buffer liberado, retomando stream');
              response.data.resume();
              clearInterval(checkBuffer);
            }
          }, 100);
        }

        ws.send(chunk);
      });

      // Quando terminar
      response.data.on('end', () => {
        const totalTtsTime = Date.now() - ttsStart;
        console.log(`‚úì √Åudio completo gerado (${totalTtsTime}ms)`);
        ws.send(JSON.stringify({ type: 'audio_end' }));
      });

      response.data.on('error', (error) => {
        console.error('‚úó Erro no stream:', error);
        ws.send(JSON.stringify({ type: 'error', message: 'Erro no stream de √°udio' }));
      });

    } catch (error) {
      console.error('‚úó Erro ao gerar TTS:', error.response?.data || error.message);
      ws.send(JSON.stringify({
        type: 'error',
        message: 'Erro ao gerar √°udio'
      }));
    }
  }
});

// ===== Fun√ß√£o auxiliar: Pegar √∫ltima transcri√ß√£o final =====
function getLastFinalTranscript(deepgramConnection) {
  return new Promise((resolve) => {
    let lastFinal = '';

    const handler = (data) => {
      const transcript = data.channel?.alternatives[0]?.transcript;
      if (transcript && data.is_final) {
        lastFinal = transcript;
      }
    };

    deepgramConnection.on('Results', handler);

    // Aguardar um pouco para coletar resultados finais
    setTimeout(() => {
      deepgramConnection.off('Results', handler);
      resolve(lastFinal);
    }, 500);
  });
}

// FIX #5: HEALTH CHECKS - Endpoint para monitoramento
app.get('/health', (req, res) => {
  const health = {
    uptime: process.uptime(),
    timestamp: Date.now(),
    activeConnections: wss.clients.size,
    memory: process.memoryUsage(),
    status: 'ok'
  };

  res.json(health);
});

app.get('/metrics', (req, res) => {
  res.json({
    activeConnections: wss.clients.size,
    uptime: process.uptime(),
    memoryUsage: process.memoryUsage(),
  });
});

// FIX #4: RATE LIMITING b√°sico - limite de conex√µes por IP
const connectionsByIP = new Map();
const MAX_CONNECTIONS_PER_IP = 5;

wss.on('connection', (ws, req) => {
  const ip = req.socket.remoteAddress;

  // Verificar limite de conex√µes
  const currentConnections = connectionsByIP.get(ip) || 0;
  if (currentConnections >= MAX_CONNECTIONS_PER_IP) {
    console.warn(`‚ö†Ô∏è  IP ${ip} excedeu limite de conex√µes (${currentConnections})`);
    ws.close(1008, 'Too many connections from this IP');
    return;
  }

  connectionsByIP.set(ip, currentConnections + 1);

  ws.on('close', () => {
    const count = connectionsByIP.get(ip) || 0;
    if (count > 0) {
      connectionsByIP.set(ip, count - 1);
    }
  });
});

// ===== Iniciar servidor =====
server.listen(PORT, () => {
  console.log(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   üéôÔ∏è  Voice AI MVP Server           ‚ïë
‚ïë                                       ‚ïë
‚ïë   Rodando em: http://localhost:${PORT}   ‚ïë
‚ïë                                       ‚ïë
‚ïë   Stack:                              ‚ïë
‚ïë   ‚Ä¢ Deepgram (STT)                    ‚ïë
‚ïë   ‚Ä¢ ChatGPT (LLM)                     ‚ïë
‚ïë   ‚Ä¢ ElevenLabs (TTS)                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
  `);
});

// FIX #10: GRACEFUL SHUTDOWN - lidar com SIGTERM/SIGINT
let isShuttingDown = false;

const gracefulShutdown = async (signal) => {
  if (isShuttingDown) return;

  console.log(`\n‚ö†Ô∏è  ${signal} received, iniciando graceful shutdown...`);
  isShuttingDown = true;

  // Parar de aceitar novas conex√µes
  server.close(() => {
    console.log('‚úì HTTP server fechado');
  });

  // Avisar todos os clientes
  console.log(`‚Üí Avisando ${wss.clients.size} clientes ativos...`);
  wss.clients.forEach((ws) => {
    try {
      ws.send(JSON.stringify({
        type: 'server_shutdown',
        message: 'Server est√° reiniciando, por favor reconecte em alguns segundos'
      }));
    } catch (error) {
      // Cliente j√° desconectou, ok
    }
  });

  // Aguardar conex√µes terminarem (max 30s)
  const shutdownTimeout = setTimeout(() => {
    console.log('‚ö†Ô∏è  Timeout atingido, for√ßando shutdown');
    process.exit(0);
  }, 30000);

  const checkInterval = setInterval(() => {
    if (wss.clients.size === 0) {
      console.log('‚úì Todas conex√µes fechadas');
      clearTimeout(shutdownTimeout);
      clearInterval(checkInterval);
      process.exit(0);
    } else {
      console.log(`‚Üí Aguardando ${wss.clients.size} conex√µes terminarem...`);
    }
  }, 1000);
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));
