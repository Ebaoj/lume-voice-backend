/**
 * Voice AI MVP Server
 *
 * Fluxo:
 * 1. Cliente envia Ã¡udio via WebSocket
 * 2. Streaming para Deepgram (STT)
 * 3. TranscriÃ§Ã£o enviada para ChatGPT (LLM)
 * 4. Resposta do ChatGPT enviada para ElevenLabs (TTS)
 * 5. Ãudio sintetizado retorna ao cliente
 */

require('dotenv').config();
const express = require('express');
const http = require('http');
const WebSocket = require('ws');
const { createClient } = require('@deepgram/sdk');
const OpenAI = require('openai');
const axios = require('axios');

// ===== ConfiguraÃ§Ã£o =====
const PORT = process.env.PORT || 3000;
const app = express();
const server = http.createServer(app);
const wss = new WebSocket.Server({ server });

// Servir arquivos estÃ¡ticos (HTML/CSS/JS do cliente)
app.use(express.static('public'));

// System prompt para o personagem "Beto"
const SYSTEM_PROMPT = `VocÃª Ã© Beto, atendente de uma cafeteria.
Seja muito breve e natural (1-2 frases). Ajude o cliente a escolher bebidas.
Fale como em uma conversa rÃ¡pida, sem formalidades.`;

// FIX #11: Limite de mensagens no histÃ³rico (evita estouro de tokens)
const MAX_CONVERSATION_HISTORY = 10;

// ===== WebSocket Handler =====
wss.on('connection', (ws) => {
  console.log('âœ“ Novo cliente conectado');

  let deepgramLive = null;
  let conversationHistory = [];
  let isProcessing = false;
  let lastFinalTranscript = ''; // Guardar Ãºltima transcriÃ§Ã£o final
  let processingTimeout = null; // Timeout para processar apÃ³s silÃªncio
  let currentTTSAbortController = null; // FIX #12: Para cancelar TTS em andamento

  // API Keys serÃ£o fornecidas pelo cliente
  let apiKeys = {
    deepgram: null,
    openai: null,
    elevenlabs: null
  };

  // Clientes dos SDKs (criados apÃ³s receber as keys)
  let deepgramClient = null;
  let openaiClient = null;

  // System prompt customizado (vem do frontend)
  let customSystemPrompt = null;

  // Voice ID customizado para ElevenLabs (vem do frontend)
  let customVoiceId = null;

  ws.on('message', async (message) => {
    try {
      // Converter Buffer para string se necessÃ¡rio
      let messageStr = message;
      if (Buffer.isBuffer(message)) {
        messageStr = message.toString('utf8');
      }

      // Mensagens podem ser comandos (string) ou Ã¡udio (buffer binÃ¡rio)
      // Verificar se Ã© JSON vÃ¡lido
      let data;
      try {
        data = JSON.parse(messageStr);
      } catch (e) {
        // NÃ£o Ã© JSON, entÃ£o Ã© Ã¡udio binÃ¡rio
        if (deepgramLive) {
          deepgramLive.send(message);
        }
        return;
      }

      // Se chegou aqui, Ã© um comando JSON
      if (data && data.type) {

        // Comando: configurar API keys
        if (data.type === 'configure') {
          console.log('â†’ Configurando API keys');

          // Limpar e validar keys
          apiKeys.deepgram = (data.keys.deepgram || '').trim();
          apiKeys.openai = (data.keys.openai || '').trim();
          apiKeys.elevenlabs = (data.keys.elevenlabs || '').trim();

          // Capturar system prompt customizado
          if (data.systemPrompt) {
            customSystemPrompt = data.systemPrompt;
            console.log('â†’ System prompt customizado recebido:', customSystemPrompt.substring(0, 100) + '...');
          }

          // Capturar voice ID customizado para ElevenLabs
          if (data.voiceId) {
            customVoiceId = data.voiceId;
            console.log('â†’ Voice ID ElevenLabs recebido:', customVoiceId);
          }

          console.log('â†’ Deepgram key:', apiKeys.deepgram.substring(0, 8) + '...' + apiKeys.deepgram.substring(apiKeys.deepgram.length - 4));
          console.log('â†’ Deepgram key length:', apiKeys.deepgram.length);

          // Inicializar clientes com as keys fornecidas
          try {
            // Criar cliente Deepgram (sem config adicional, igual ao test-deepgram.js que funciona)
            deepgramClient = createClient(apiKeys.deepgram);

            openaiClient = new OpenAI({
              apiKey: apiKeys.openai,
            });

            ws.send(JSON.stringify({
              type: 'configured',
              message: 'APIs configuradas com sucesso!'
            }));
            console.log('âœ“ APIs configuradas');
          } catch (error) {
            console.error('âœ— Erro ao criar clientes:', error);
            ws.send(JSON.stringify({
              type: 'error',
              message: 'Erro ao configurar APIs: ' + error.message
            }));
          }
          return;
        }

        // Comando: iniciar streaming de Ã¡udio
        if (data.type === 'start') {
          console.log('â†’ Iniciando sessÃ£o de Ã¡udio');

          // Verificar se as APIs foram configuradas
          if (!deepgramClient || !openaiClient) {
            ws.send(JSON.stringify({
              type: 'error',
              message: 'Configure as API keys primeiro!'
            }));
            return;
          }

          // Verificar se a key do Deepgram estÃ¡ vÃ¡lida
          if (!apiKeys.deepgram || apiKeys.deepgram.length < 10) {
            ws.send(JSON.stringify({
              type: 'error',
              message: 'API key do Deepgram invÃ¡lida!'
            }));
            return;
          }

          // FIX #1: MEMORY LEAK - Limpar listeners antigos antes de criar nova conexÃ£o
          if (deepgramLive) {
            console.log('â†’ Limpando conexÃ£o Deepgram anterior...');
            deepgramLive.removeAllListeners();
            deepgramLive.finish();
            deepgramLive = null;
          }

          // Criar conexÃ£o de streaming com Deepgram
          console.log('â†’ Criando conexÃ£o Deepgram...');
          try {
            deepgramLive = deepgramClient.listen.live({
              model: 'nova-2',
              language: 'pt-BR',
              encoding: 'linear16',
              sample_rate: 16000,
              interim_results: true,
              vad_events: true,
              // ConfiguraÃ§Ãµes para evitar interrupÃ§Ãµes prematuras
              endpointing: 800, // Esperar 800ms de silÃªncio antes de considerar fim de fala
              utterance_end_ms: 1200, // Tempo extra para pausas longas (pensando)
            });
            console.log('âœ“ ConexÃ£o Deepgram criada');
          } catch (error) {
            console.error('âœ— Erro ao criar conexÃ£o live:', error);
            ws.send(JSON.stringify({
              type: 'error',
              message: 'Erro ao criar conexÃ£o com Deepgram: ' + error.message
            }));
            return;
          }

          // ===== Deepgram Event Handlers =====
          console.log('â†’ Registrando event handlers do Deepgram...');

          // Quando Deepgram estiver pronto
          deepgramLive.on('open', () => {
            console.log('âœ… âœ… âœ… Deepgram OPEN event disparado! ConexÃ£o estabelecida!');
            // SÃ³ agora avisar o cliente que pode comeÃ§ar a enviar Ã¡udio
            ws.send(JSON.stringify({ type: 'deepgram_ready' }));
          });

          // Resultado de transcriÃ§Ã£o (parcial ou final)
          deepgramLive.on('Results', async (data) => {
            console.log('ðŸ“Š Results event recebido');
            const transcript = data.channel?.alternatives[0]?.transcript;

            if (transcript && transcript.trim().length > 0) {
              const isFinal = data.is_final;

              // Enviar transcriÃ§Ã£o para o cliente (para debug visual)
              ws.send(JSON.stringify({
                type: 'transcript',
                text: transcript,
                isFinal: isFinal
              }));

              console.log(`${isFinal ? 'âœ“' : '...'} TranscriÃ§Ã£o: ${transcript}`);

              // Se Ã© final, guardar e agendar processamento
              if (isFinal) {
                lastFinalTranscript = transcript;

                // Limpar timeout anterior
                if (processingTimeout) {
                  clearTimeout(processingTimeout);
                }

                // Agendar processamento apÃ³s 1000ms de silÃªncio (dar tempo para pensar)
                processingTimeout = setTimeout(async () => {
                  if (!isProcessing && lastFinalTranscript && lastFinalTranscript.trim().length > 0) {
                    const transcriptToProcess = lastFinalTranscript;
                    lastFinalTranscript = '';

                    isProcessing = true;
                    ws.send(JSON.stringify({ type: 'status', message: 'Processando...' }));

                    console.log(`ðŸ“ Processando transcriÃ§Ã£o: "${transcriptToProcess}"`);
                    await processWithGPT(transcriptToProcess, ws);
                    isProcessing = false;
                  }
                }, 1000);
              }
            }
          });

          // Utterance End - usuÃ¡rio parou de falar
          deepgramLive.on('UtteranceEnd', async () => {
            console.log('â†’ Fim de fala detectado');

            if (isProcessing) {
              console.log('âš  JÃ¡ processando uma resposta, ignorando...');
              return;
            }

            // Usar a Ãºltima transcriÃ§Ã£o final guardada
            if (lastFinalTranscript && lastFinalTranscript.trim().length > 0) {
              const transcriptToProcess = lastFinalTranscript;
              lastFinalTranscript = ''; // Limpar para nÃ£o processar novamente

              isProcessing = true;
              ws.send(JSON.stringify({ type: 'status', message: 'Processando...' }));

              console.log(`ðŸ“ Processando transcriÃ§Ã£o: "${transcriptToProcess}"`);

              // Processar com ChatGPT e gerar resposta em voz
              await processWithGPT(transcriptToProcess, ws);

              isProcessing = false;
            } else {
              console.log('âš  Nenhuma transcriÃ§Ã£o final para processar');
            }
          });

          // Erros do Deepgram
          deepgramLive.on('error', (error) => {
            console.error('âŒ âŒ âŒ ERRO DEEPGRAM:', {
              type: typeof error,
              message: error.message,
              error: JSON.stringify(error, null, 2),
              keys: Object.keys(error),
              errorString: error.toString(),
              stack: error.stack
            });

            // Tentar extrair mais informaÃ§Ãµes
            if (error.event) {
              console.error('  Error event:', error.event);
            }
            if (error.reason) {
              console.error('  Reason:', error.reason);
            }

            ws.send(JSON.stringify({
              type: 'error',
              message: `Erro no STT: ${error.message || error.reason || 'Verifique sua API key do Deepgram'}`
            }));
          });

          deepgramLive.on('close', (closeEvent) => {
            console.error('ðŸ”´ DEEPGRAM CLOSE EVENT:', {
              type: closeEvent.type,
              code: closeEvent.code,
              reason: closeEvent.reason,
              wasClean: closeEvent.wasClean,
              timestamp: closeEvent.timeStamp,
              all: JSON.stringify(closeEvent, null, 2)
            });
          });

          deepgramLive.on('warning', (warning) => {
            console.warn('âš ï¸ âš ï¸ WARNING DEEPGRAM:', warning);
          });

          deepgramLive.on('Metadata', (metadata) => {
            console.log('â„¹ï¸ â„¹ï¸ METADATA DEEPGRAM:', metadata);
          });

          // Tentar capturar eventos de mensagem
          if (deepgramLive._ws) {
            console.log('â†’ WebSocket interno encontrado, adicionando listeners...');
            deepgramLive._ws.on('message', (msg) => {
              console.log('ðŸ“¨ WS Message:', msg.toString());
            });
          }

          console.log('âœ“ Todos os event handlers registrados');
        }

        // FIX #12: Comando: interromper bot (usuÃ¡rio comeÃ§ou a falar)
        if (data.type === 'interrupt') {
          console.log('âš ï¸  InterrupÃ§Ã£o detectada - cancelando TTS em andamento');

          // Cancelar TTS em andamento
          if (currentTTSAbortController) {
            currentTTSAbortController.abort();
            currentTTSAbortController = null;
          }

          // Avisar cliente para limpar fila de Ã¡udio
          ws.send(JSON.stringify({ type: 'clear_audio_queue' }));

          isProcessing = false;
          return;
        }

        // Comando: parar streaming
        if (data.type === 'stop') {
          console.log('â†’ Encerrando sessÃ£o de Ã¡udio');
          if (processingTimeout) {
            clearTimeout(processingTimeout);
            processingTimeout = null;
          }
          if (currentTTSAbortController) {
            currentTTSAbortController.abort();
            currentTTSAbortController = null;
          }
          if (deepgramLive) {
            deepgramLive.finish();
            deepgramLive = null;
          }
          conversationHistory = [];
          lastFinalTranscript = '';
          isProcessing = false;
        }
      }
    } catch (error) {
      console.error('âœ— Erro ao processar mensagem:', error);
      ws.send(JSON.stringify({ type: 'error', message: error.message }));
    }
  });

  // Cliente desconectou
  ws.on('close', () => {
    console.log('âœ— Cliente desconectado');
    if (deepgramLive) {
      deepgramLive.finish();
    }
  });

  // ===== FunÃ§Ã£o: Processar com ChatGPT STREAMING e gerar TTS =====
  async function processWithGPT(userMessage, ws) {
    const startTime = Date.now();

    try {
      // FIX #9: SANITIZAR LOGS - nÃ£o logar conteÃºdo das mensagens (pode ter PII)
      console.log(`â†’ Enviando para ChatGPT (length: ${userMessage.length})`);

      // Adicionar mensagem do usuÃ¡rio ao histÃ³rico
      conversationHistory.push({
        role: 'user',
        content: userMessage
      });

      // FIX #11: Limitar histÃ³rico (evita estouro de contexto e custo alto)
      if (conversationHistory.length > MAX_CONVERSATION_HISTORY) {
        conversationHistory = conversationHistory.slice(-MAX_CONVERSATION_HISTORY);
        console.log(`âš ï¸  HistÃ³rico limitado a ${MAX_CONVERSATION_HISTORY} mensagens`);
      }

      // Preparar mensagens incluindo system prompt
      const messages = [
        {
          role: 'system',
          content: customSystemPrompt || SYSTEM_PROMPT // Usar prompt customizado ou fallback para padrÃ£o
        },
        ...conversationHistory
      ];

      // FIX #6: TIMEOUTS - Chamar OpenAI com timeout (evita travar se API ficar lenta)
      const gptStart = Date.now();

      // Timeout manual (OpenAI SDK nÃ£o tem timeout configurÃ¡vel no streaming)
      const timeoutPromise = new Promise((_, reject) => {
        setTimeout(() => reject(new Error('OpenAI timeout apÃ³s 15s')), 15000);
      });

      const streamPromise = openaiClient.chat.completions.create({
        model: 'gpt-4o', // Modelo mais inteligente para personagens mais profundos
        max_tokens: 250, // Mais espaÃ§o para respostas elaboradas
        temperature: 0.8, // Um pouco mais criativo
        messages: messages,
        stream: true,
        stream_options: { include_usage: true }, // Incluir informaÃ§Ãµes de token usage
      });

      const stream = await Promise.race([streamPromise, timeoutPromise]);

      let fullResponse = '';
      let sentenceBuffer = '';
      let firstChunk = true;
      let sentenceCount = 0;
      let tokenUsage = null; // Armazenar info de usage

      // Processar stream chunk por chunk
      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';

        // Capturar usage info (vem no Ãºltimo chunk)
        if (chunk.usage) {
          tokenUsage = chunk.usage;
        }

        if (content) {
          if (firstChunk) {
            const firstTokenTime = Date.now() - gptStart;
            console.log(`âš¡ Primeiro token ChatGPT (${firstTokenTime}ms)`);
            firstChunk = false;
          }

          fullResponse += content;
          sentenceBuffer += content;

          // Detectar fim de frase (., ?, !, \n)
          const sentenceEndMatch = sentenceBuffer.match(/[.!?]\s|[.!?]$|\n/);
          if (sentenceEndMatch) {
            const sentence = sentenceBuffer.trim();
            if (sentence.length > 0) {
              sentenceCount++;
              // FIX #9: NÃ£o logar conteÃºdo da frase (PII)
              console.log(`ðŸ“¤ Frase ${sentenceCount} (${sentence.length} chars)`);

              // Enviar frase para o cliente (debug visual)
              ws.send(JSON.stringify({
                type: 'response_partial',
                text: sentence
              }));

              // ðŸš€ INOVAÃ‡ÃƒO: Gerar TTS da frase imediatamente (await para sequencial)
              await generateTTS(sentence, ws).catch(err => {
                console.error('Erro TTS frase:', err);
              });

              sentenceBuffer = ''; // Limpar buffer
            }
          }
        }
      }

      // Processar Ãºltimo pedaÃ§o se sobrou
      if (sentenceBuffer.trim().length > 0) {
        console.log(`ðŸ“¤ Frase final: "${sentenceBuffer.trim()}"`);
        ws.send(JSON.stringify({
          type: 'response_partial',
          text: sentenceBuffer.trim()
        }));
        await generateTTS(sentenceBuffer.trim(), ws);
      }

      const gptTime = Date.now() - gptStart;
      // FIX #9: NÃ£o logar resposta completa (PII)
      console.log(`âœ“ ChatGPT completo (${gptTime}ms, ${fullResponse.length} chars)`);

      // Adicionar resposta ao histÃ³rico
      conversationHistory.push({
        role: 'assistant',
        content: fullResponse
      });

      // Enviar resposta completa
      ws.send(JSON.stringify({
        type: 'response',
        text: fullResponse
      }));

      // Enviar informaÃ§Ãµes de token usage para o frontend
      if (tokenUsage) {
        ws.send(JSON.stringify({
          type: 'token_usage',
          usage: {
            prompt_tokens: tokenUsage.prompt_tokens,
            completion_tokens: tokenUsage.completion_tokens,
            total_tokens: tokenUsage.total_tokens
          }
        }));
        console.log(`ðŸ“Š Tokens: ${tokenUsage.prompt_tokens} input + ${tokenUsage.completion_tokens} output = ${tokenUsage.total_tokens} total`);
      }

      const totalTime = Date.now() - startTime;
      console.log(`â±ï¸ Tempo total pipeline: ${totalTime}ms`);

    } catch (error) {
      console.error('âœ— Erro ao processar com ChatGPT:', error);
      ws.send(JSON.stringify({
        type: 'error',
        message: 'Erro ao processar com LLM'
      }));
    }
  }

  // ===== FunÃ§Ã£o: Gerar TTS com ElevenLabs (Streaming) =====
  async function generateTTS(text, ws) {
    const ttsStart = Date.now();

    try {
      console.log(`â†’ Gerando Ã¡udio com ElevenLabs (${text.length} chars)...`);

      // Usar voice ID customizado do frontend, ou fallback para env var ou padrÃ£o
      const voiceId = customVoiceId || process.env.ELEVENLABS_VOICE_ID || '21m00Tcm4TlvDq8ikWAM';
      console.log(`â†’ Usando Voice ID: ${voiceId}`);
      const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream`;

      // FIX #12: AbortController para cancelar TTS se usuÃ¡rio interromper
      currentTTSAbortController = new AbortController();

      // FIX #6: Timeout para ElevenLabs (evita travar)
      const response = await axios.post(url, {
        text: text,
        model_id: 'eleven_turbo_v2_5',
        voice_settings: {
          stability: 0.5,
          similarity_boost: 0.75
        },
        optimize_streaming_latency: 4
      }, {
        headers: {
          'Accept': 'audio/mpeg',
          'xi-api-key': apiKeys.elevenlabs,
          'Content-Type': 'application/json'
        },
        responseType: 'stream',
        timeout: 10000, // 10s timeout
        signal: currentTTSAbortController.signal // Permitir cancelamento
      });

      const ttsTime = Date.now() - ttsStart;
      console.log(`âœ“ Stream de Ã¡udio iniciado (${ttsTime}ms)`);

      // Enviar sinal de inÃ­cio
      ws.send(JSON.stringify({ type: 'audio_start' }));

      // FIX #8: Fazer streaming dos chunks de Ã¡udio com BACKPRESSURE
      let firstChunk = true;
      response.data.on('data', (chunk) => {
        if (firstChunk) {
          const firstChunkTime = Date.now() - ttsStart;
          console.log(`ðŸŽµ Primeiro chunk de Ã¡udio (${firstChunkTime}ms)`);
          firstChunk = false;
        }

        // Verificar backpressure (buffer do WebSocket)
        if (ws.bufferedAmount > 1024 * 1024) { // 1MB
          console.warn('âš ï¸  Backpressure detectada, pausando stream');
          response.data.pause();

          // Retomar quando buffer diminuir
          const checkBuffer = setInterval(() => {
            if (ws.bufferedAmount < 512 * 1024) { // 512KB
              console.log('âœ“ Buffer liberado, retomando stream');
              response.data.resume();
              clearInterval(checkBuffer);
            }
          }, 100);
        }

        ws.send(chunk);
      });

      // Quando terminar
      response.data.on('end', () => {
        const totalTtsTime = Date.now() - ttsStart;
        console.log(`âœ“ Ãudio completo gerado (${totalTtsTime}ms)`);
        ws.send(JSON.stringify({ type: 'audio_end' }));
      });

      response.data.on('error', (error) => {
        console.error('âœ— Erro no stream:', error);
        ws.send(JSON.stringify({ type: 'error', message: 'Erro no stream de Ã¡udio' }));
      });

    } catch (error) {
      console.error('âœ— Erro ao gerar TTS:', error.response?.data || error.message);
      ws.send(JSON.stringify({
        type: 'error',
        message: 'Erro ao gerar Ã¡udio'
      }));
    }
  }
});

// ===== FunÃ§Ã£o auxiliar: Pegar Ãºltima transcriÃ§Ã£o final =====
function getLastFinalTranscript(deepgramConnection) {
  return new Promise((resolve) => {
    let lastFinal = '';

    const handler = (data) => {
      const transcript = data.channel?.alternatives[0]?.transcript;
      if (transcript && data.is_final) {
        lastFinal = transcript;
      }
    };

    deepgramConnection.on('Results', handler);

    // Aguardar um pouco para coletar resultados finais
    setTimeout(() => {
      deepgramConnection.off('Results', handler);
      resolve(lastFinal);
    }, 500);
  });
}

// FIX #5: HEALTH CHECKS - Endpoint para monitoramento
app.get('/health', (req, res) => {
  const health = {
    uptime: process.uptime(),
    timestamp: Date.now(),
    activeConnections: wss.clients.size,
    memory: process.memoryUsage(),
    status: 'ok'
  };

  res.json(health);
});

app.get('/metrics', (req, res) => {
  res.json({
    activeConnections: wss.clients.size,
    uptime: process.uptime(),
    memoryUsage: process.memoryUsage(),
  });
});

// FIX #4: RATE LIMITING bÃ¡sico - limite de conexÃµes por IP
const connectionsByIP = new Map();
const MAX_CONNECTIONS_PER_IP = 5;

wss.on('connection', (ws, req) => {
  const ip = req.socket.remoteAddress;

  // Verificar limite de conexÃµes
  const currentConnections = connectionsByIP.get(ip) || 0;
  if (currentConnections >= MAX_CONNECTIONS_PER_IP) {
    console.warn(`âš ï¸  IP ${ip} excedeu limite de conexÃµes (${currentConnections})`);
    ws.close(1008, 'Too many connections from this IP');
    return;
  }

  connectionsByIP.set(ip, currentConnections + 1);

  ws.on('close', () => {
    const count = connectionsByIP.get(ip) || 0;
    if (count > 0) {
      connectionsByIP.set(ip, count - 1);
    }
  });
});

// ===== Iniciar servidor =====
server.listen(PORT, () => {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ðŸŽ™ï¸  Voice AI MVP Server           â•‘
â•‘                                       â•‘
â•‘   Rodando em: http://localhost:${PORT}   â•‘
â•‘                                       â•‘
â•‘   Stack:                              â•‘
â•‘   â€¢ Deepgram (STT)                    â•‘
â•‘   â€¢ ChatGPT (LLM)                     â•‘
â•‘   â€¢ ElevenLabs (TTS)                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  `);
});

// FIX #10: GRACEFUL SHUTDOWN - lidar com SIGTERM/SIGINT
let isShuttingDown = false;

const gracefulShutdown = async (signal) => {
  if (isShuttingDown) return;

  console.log(`\nâš ï¸  ${signal} received, iniciando graceful shutdown...`);
  isShuttingDown = true;

  // Parar de aceitar novas conexÃµes
  server.close(() => {
    console.log('âœ“ HTTP server fechado');
  });

  // Avisar todos os clientes
  console.log(`â†’ Avisando ${wss.clients.size} clientes ativos...`);
  wss.clients.forEach((ws) => {
    try {
      ws.send(JSON.stringify({
        type: 'server_shutdown',
        message: 'Server estÃ¡ reiniciando, por favor reconecte em alguns segundos'
      }));
    } catch (error) {
      // Cliente jÃ¡ desconectou, ok
    }
  });

  // Aguardar conexÃµes terminarem (max 30s)
  const shutdownTimeout = setTimeout(() => {
    console.log('âš ï¸  Timeout atingido, forÃ§ando shutdown');
    process.exit(0);
  }, 30000);

  const checkInterval = setInterval(() => {
    if (wss.clients.size === 0) {
      console.log('âœ“ Todas conexÃµes fechadas');
      clearTimeout(shutdownTimeout);
      clearInterval(checkInterval);
      process.exit(0);
    } else {
      console.log(`â†’ Aguardando ${wss.clients.size} conexÃµes terminarem...`);
    }
  }, 1000);
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));
