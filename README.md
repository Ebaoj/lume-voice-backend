# ğŸ™ï¸ Lume Voice AI - Backend

Backend WebSocket para o sistema de Voice AI do Lume. Processa conversas de voz usando:

- **Deepgram** (Speech-to-Text)
- **OpenAI GPT-4** (LLM conversacional)
- **ElevenLabs** (Text-to-Speech)

## ğŸš€ Deploy no Render.com

Veja o guia completo em: [RENDER_DEPLOY.md](./RENDER_DEPLOY.md)

## ğŸ’» Desenvolvimento Local

```bash
# Instalar dependÃªncias
npm install

# Iniciar servidor
npm start

# Servidor rodarÃ¡ em: http://localhost:3001
```

## ğŸ“¦ DependÃªncias

- express - Servidor HTTP
- ws - WebSocket server
- @deepgram/sdk - Speech-to-Text
- openai - LLM conversacional
- axios - HTTP client
- dotenv - VariÃ¡veis de ambiente

## ğŸ”§ VariÃ¡veis de Ambiente

NÃ£o hÃ¡ variÃ¡veis de ambiente obrigatÃ³rias. As API keys sÃ£o enviadas pelo frontend via WebSocket.

Opcional:
- `PORT` - Porta do servidor (padrÃ£o: 3000)
- `ELEVENLABS_VOICE_ID` - ID da voz do ElevenLabs (padrÃ£o: 21m00Tcm4TlvDq8ikWAM)

## ğŸ“¡ Endpoints

- `GET /health` - Health check (retorna status, uptime, memÃ³ria)
- `GET /metrics` - MÃ©tricas do servidor (conexÃµes ativas, uptime)
- `WS /` - WebSocket endpoint principal

## ğŸ—ï¸ Arquitetura

1. Cliente conecta via WebSocket
2. Frontend envia API keys via mensagem `configure`
3. Backend inicia streaming do Deepgram
4. Ãudio do usuÃ¡rio â†’ Deepgram â†’ TranscriÃ§Ã£o
5. TranscriÃ§Ã£o â†’ GPT-4 (streaming) â†’ Resposta
6. Resposta (frase por frase) â†’ ElevenLabs â†’ Ãudio
7. Ãudio retorna ao cliente via WebSocket

## ğŸ”’ SeguranÃ§a

- Rate limiting: MÃ¡ximo 5 conexÃµes por IP
- Graceful shutdown: Avisa clientes antes de desligar
- Backpressure: Pausa streaming se buffer do WebSocket encher
- Timeout: 15s para OpenAI, 10s para ElevenLabs

## ğŸ“ LicenÃ§a

MIT
